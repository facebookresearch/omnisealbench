{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83603f80-f77e-490c-b567-052c6cb73882",
   "metadata": {},
   "source": [
    "# Watermarking custom model\n",
    "This notebook shows how we can use Omniseal Bench Python APIs to add a new model and run the evaluation tasks on different datasets. We demonstrate with audio but this applies to all modalities too.\n",
    "\n",
    "## Basic Concepts:\n",
    "### Task:\n",
    "\n",
    "The Task defines the dataset to be used for the evaluation, how to load data (batch size, padding, etc.) and metrics to run. The task type can be one of the three:\n",
    "\n",
    "- **generation**: Run a generator over specific dataset to watermark each of its items, and return the quality metrics of the watermarked audios.\n",
    "\n",
    "- **detection**: Apply a specific set of attacks over a watermarked dataset, then run detector and report the detection scores (robustness) and as well as quality metrics for each attack.\n",
    "\n",
    "- **default**: Run end-to-end genration and detection.\n",
    "\n",
    "### Model:\n",
    "A model is a wrapper over the watermarking model. A model in Omniseal Bench can fall into 3 kinds: Generator, Detector, or both. A Generator is any model that implements the `generate_watermark()` , a Detector is any model that implments the `detect_watermark()` with a specific signature as belows.\n",
    "\n",
    "\n",
    "### Task - Model compatibility:\n",
    "\n",
    "- A **generation** task can only evaluate a Generator (model that implements `generate_watermark()` method).\n",
    "\n",
    "- A **detection** task can only evaluate a Detector (model that implements `detect_watermark()` method).\n",
    "\n",
    "- A **default** task can only evaluate a model that implements both `generate_watermark()` and `detect_watermark()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72b6ee-25f1-41d1-aacc-70b851b32659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Jupyter kernels check TORCH_DISTRIBUTED_DEBUG and throw an error if not found\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"OFF\"\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8485a1f-f28a-47c7-8fa2-30584d8b71a5",
   "metadata": {},
   "source": [
    "## Running example:\n",
    "\n",
    "The steps to build a custom model:\n",
    "\n",
    "#### Step 1: Define the model class(es)\n",
    "A model class in Omniseal Bench can fall into 3 types: Generator, Detector, or both. A Generator is any class that implements the `generate_watermark()` , a Detector is any class that implments the `detect_watermark()` with a specific signature as belows.\n",
    "\n",
    "#### Step 2: Define the builder function:\n",
    "  \n",
    "  - The builder function is a function that returns an object of the model class. The function name must be strictly either \"build_generator()\" (that returns a Generator), \"build_detector()\" (that returns a Detector), or build_model()\" (that returns a class being both Generator and Detector).\n",
    "\n",
    "  - The function can have any parameters, but should contain at least one parameter \"device\" which defines which device the model object will be placed too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6f82f-ec88-4b58-9e08-cb5c4ae85eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Put the following code in a module file (toy_audio.py)\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# STEP 1: Define the model\n",
    "# The compatibility between model and the task:\n",
    "# For the model to be evaluated in a generation task (\"generation\"), we must implement get_watermark()\n",
    "# For the model to be evaluated in a detection task (\"detection\"), we must implement detect_watermark()\n",
    "# For the model to be evaluated in an end-to-end task (\"default\"), we must implement both functions\n",
    "class ToyAudioWatermark:\n",
    "    \n",
    "    model: nn.Module\n",
    "    \n",
    "    def __init__(self, model: torch.nn.Module, alpha: float = 0.0001, M: float = 1.0, nbits: int = 16):\n",
    "        self.model = model\n",
    "        \n",
    "        # A wrapper can have any additional arguments. These arguments should be set in the builder func\n",
    "        self.alpha = alpha\n",
    "        self.M = M\n",
    "        \n",
    "        # Each model should have an attribute 'nbits'. If the model does not have this attribute,\n",
    "        # we must set the value `message_size` in the task. If Omniseal could not find information \n",
    "        # from either model or the task, it will raise the ValueError\n",
    "        self.nbits = nbits\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate_watermark(\n",
    "        self,\n",
    "        contents: torch.Tensor,\n",
    "        message: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # A generate_watermark() must specific signature:\n",
    "        # Args:\n",
    "        #  - contents: a torch.Tensor (with batch dimension at dim=0) or a list of torch.Tensor (each without batch dimension)\n",
    "        # - message: a torch.Tensor or a numpy array\n",
    "        # Return:\n",
    "        # - Should have the same data type as 'contents' with the same dimension\n",
    "\n",
    "        # A dummy implementation of watermark for demo. Here we just, we just use a constant value M\n",
    "        hidden = torch.full_like(contents, self.M, dtype=contents.dtype, device=contents.device)\n",
    "        return contents + self.alpha * hidden\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def detect_watermark(\n",
    "        self,\n",
    "        contents: torch.Tensor,\n",
    "        detection_threshold: float = 0.0,\n",
    "        message_threshold: float = 0.0,\n",
    "        detection_bits: Optional[int] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # A detect_watermark() must have a specific signature:\n",
    "        # Args:\n",
    "        #  - contents: a torch.Tensor (with batch dimension at dim=0) or a list of torch.Tensor (each without batch dimension)\n",
    "        #  - message_threshold: threshold used to convert the watermark output (probability\n",
    "        #    of each bits being 0 or 1) into the binary n-bit message.\n",
    "        #  - detection_threshold: threshold to convert the softmax output to binary indicating\n",
    "        #    the probability of the content being watermarked\n",
    "        #  - detection_bits: number of bits reserved for calculating detection accuracy. \n",
    "        # Returns:\n",
    "        #  - a dictionary of with some keys such as:\n",
    "        #    - \"prediction\": The prediction probability of the content being watermarked or not. The dimension should be 1 for batch size of `B`.\n",
    "        #    - \"message\": The secret message of dimension `B x nbits`\n",
    "        #    - \"detection_bits\": The list of bits reserved to calculating the detection accuracy.\n",
    "        #   \n",
    "        #    One of \"prediction\" and \"detection_bits\" must be provided. \"message\" is optional\n",
    "        #    If \"message\" is returned, Omniseal Bench will compute message accuracy scores: \"bit_acc\", \"word_acc\", \"p_value\", \"capacity\", and \"log10_p_value\"\n",
    "        #    Otherwise, these metrics will be skipped\n",
    "        \n",
    "        B = len(contents)\n",
    "\n",
    "        # Dummy implementation\n",
    "        if self.alpha == 0:            \n",
    "            return {\n",
    "                \"prediction\": torch.zeros((B,), device=contents.device),  # prediction probablity is a 1-dim vector\n",
    "                \"message\": torch.zeros((B, self.nbits), device=contents.device)  # Dummy message for demonstration\n",
    "            }\n",
    "        return {\n",
    "            \"prediction\": torch.ones((B,), device=contents.device),  # # prediction probablity is a \n",
    "            \"message\": torch.ones((B, self.nbits), dtype=contents.dtype, device=contents.device)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "# STEP 2: Define the builder function.\n",
    "# \n",
    "# The function can have any parameters, but should contain at least one parameter \"device\" which defines which device the model object will be placed too.\n",
    "# It is advisable to have the parameters() of the model class __init__() match the arguments of this function.\n",
    "def build_model(alpha: float = 0.0001, M: float = 1.0, nbits: int = 16, device: str = \"cpu\") -> ToyWatermark:\n",
    "    \n",
    "    model = torch.nn.Identity() # no actual model, just a placeholder\n",
    "    \n",
    "    return ToyWatermark(model=model, alpha=alpha, M=M, nbits=nbits).eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449ef69",
   "metadata": {},
   "source": [
    "Finally, we run step 3. We demonstrate with audio but this applies to all modalities too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82661332",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = load_module_from_file(\"my_module\", \"toy_audio.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c7257",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = importlib.import_module(\"my_module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/tuantran/.conda/envs/omnisealbench/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AudioWatermarkAttacksAndDetection with attack: no-attack\n",
      "Running AudioWatermarkAttacksAndDetection with attack: updownresample\n",
      "Running AudioWatermarkAttacksAndDetection with attack: bandpass_filter\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_0.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_0.6\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_0.7\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_0.8\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_0.9\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_1.0\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_1.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_1.2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_1.25\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_1.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_1.4\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed__speed_factor_1.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: speed_julius__speed_1.25\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.1__duration_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.1__duration_0.2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.1__duration_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.1__duration_0.4\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.1__duration_0.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.2__duration_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.2__duration_0.2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.2__duration_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.2__duration_0.4\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.2__duration_0.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.3__duration_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.3__duration_0.2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.3__duration_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.3__duration_0.4\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.3__duration_0.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.4__duration_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.4__duration_0.2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.4__duration_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.4__duration_0.4\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.4__duration_0.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.5__duration_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.5__duration_0.2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.5__duration_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.5__duration_0.4\n",
      "Running AudioWatermarkAttacksAndDetection with attack: echo__volume_0.5__duration_0.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: random_noise__noise_std_0.001\n",
      "Running AudioWatermarkAttacksAndDetection with attack: random_noise__noise_std_0.01\n",
      "Running AudioWatermarkAttacksAndDetection with attack: random_noise__noise_std_0.05\n",
      "Running AudioWatermarkAttacksAndDetection with attack: random_noise__noise_std_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: random_noise__noise_std_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: pink_noise__noise_std_0.01\n",
      "Running AudioWatermarkAttacksAndDetection with attack: pink_noise__noise_std_0.05\n",
      "Running AudioWatermarkAttacksAndDetection with attack: pink_noise__noise_std_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: pink_noise__noise_std_0.2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: pink_noise__noise_std_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: pink_noise__noise_std_0.5\n",
      "Running AudioWatermarkAttacksAndDetection with attack: pink_noise__noise_std_1.0\n",
      "Running AudioWatermarkAttacksAndDetection with attack: lowpass_filter__cutoff_freq_500\n",
      "Running AudioWatermarkAttacksAndDetection with attack: lowpass_filter__cutoff_freq_1000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: lowpass_filter__cutoff_freq_1500\n",
      "Running AudioWatermarkAttacksAndDetection with attack: lowpass_filter__cutoff_freq_2000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: lowpass_filter__cutoff_freq_3000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: lowpass_filter__cutoff_freq_4000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: lowpass_filter__cutoff_freq_5000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: highpass_filter__cutoff_freq_500\n",
      "Running AudioWatermarkAttacksAndDetection with attack: highpass_filter__cutoff_freq_1000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: highpass_filter__cutoff_freq_1500\n",
      "Running AudioWatermarkAttacksAndDetection with attack: highpass_filter__cutoff_freq_2000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: highpass_filter__cutoff_freq_4000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: highpass_filter__cutoff_freq_8000\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_10\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_20\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_30\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_40\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_50\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_60\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_70\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_80\n",
      "Running AudioWatermarkAttacksAndDetection with attack: boost_audio__amount_90\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_10\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_20\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_30\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_40\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_50\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_60\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_70\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_80\n",
      "Running AudioWatermarkAttacksAndDetection with attack: duck_audio__amount_90\n",
      "Running AudioWatermarkAttacksAndDetection with attack: shush__fraction_0.001\n",
      "Running AudioWatermarkAttacksAndDetection with attack: shush__fraction_0.01\n",
      "Running AudioWatermarkAttacksAndDetection with attack: shush__fraction_0.1\n",
      "Running AudioWatermarkAttacksAndDetection with attack: shush__fraction_0.3\n",
      "Running AudioWatermarkAttacksAndDetection with attack: smooth__window_size_2\n",
      "Running AudioWatermarkAttacksAndDetection with attack: smooth__window_size_4\n",
      "Running AudioWatermarkAttacksAndDetection with attack: smooth__window_size_8\n",
      "Running AudioWatermarkAttacksAndDetection with attack: smooth__window_size_10\n",
      "Running AudioWatermarkAttacksAndDetection with attack: smooth__window_size_20\n",
      "Running AudioWatermarkAttacksAndDetection with attack: smooth__window_size_40\n",
      "Running AudioWatermarkAttacksAndDetection with attack: aac_compression__bitrate_12k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: aac_compression__bitrate_24k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: aac_compression__bitrate_32k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: aac_compression__bitrate_64k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: aac_compression__bitrate_128k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: aac_compression__bitrate_256k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: mp3_compression__bitrate_12k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: mp3_compression__bitrate_24k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: mp3_compression__bitrate_32k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: mp3_compression__bitrate_64k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: mp3_compression__bitrate_128k\n",
      "Running AudioWatermarkAttacksAndDetection with attack: mp3_compression__bitrate_256k\n"
     ]
    }
   ],
   "source": [
    "# Example task that evaluates a custom model\n",
    "\n",
    "from omnisealbench import task, get_model\n",
    "\n",
    "\n",
    "custom_task = task(\n",
    "    \"default\",\n",
    "    modality=\"audio\",\n",
    "    \n",
    "    # Dataset options\n",
    "    dataset_type=\"local\",  # (Only supported in Audio) type: 'hf', 'local'\n",
    "    dataset_dir=\"../examples/\",\n",
    "    audio_pattern=\"*.wav\",\n",
    "    # if dataset_type = 'hf'\n",
    "    # dataset_name=\"hf-internal-testing/librispeech_asr_dummy\",\n",
    "    # dataset_hf_subset=\"clean\",\n",
    "    # dataset_split=\"validation[:4]\",\n",
    "\n",
    "    # Data loading options:\n",
    "    sample_rate=24_000,\n",
    "    padding_strategy=\"longest\",  # Supported padding: 'fixed', 'longest'\n",
    "    # If padding_strategy='fixed', we need to specify max_length to pad or truncate all audios to a fixed length\n",
    "    # max_length=24000,  # 2 seconds of audio at 24kHz \n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    "    attacks=\"all\",\n",
    "    \n",
    "    # Output options:\n",
    "    # result_dir=\"toy_result\",  # Directory to store final output\n",
    "    # cache_dir=\"to_wm\",  # Directory where the intermediate watermaked contents and secret messges are stored\n",
    ")\n",
    "\n",
    "# If passing the path of a Python file, Omniseal Bench will search for build_model(), build_generator() or build_detector()\n",
    "# in the file and and call that function\n",
    "model = get_model(\"models/toy_audio.py\", alpha=0.5, nbits=100, device=\"cuda\")\n",
    "\n",
    "avg_metrics, raw_results = custom_task(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239e030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'watermark_det_score': AverageMetric(avg=0.375, count=32, square=0.140625, avg_ci_fn=None),\n",
       " 'watermark_det': AverageMetric(avg=0.0, count=32, square=0.0, avg_ci_fn=None),\n",
       " 'fake_det_score': AverageMetric(avg=0.375, count=32, square=0.140625, avg_ci_fn=None),\n",
       " 'fake_det': AverageMetric(avg=0.0, count=32, square=0.0, avg_ci_fn=None),\n",
       " 'bit_acc': AverageMetric(avg=0.421875, count=32, square=0.20703125, avg_ci_fn=None),\n",
       " 'word_acc': AverageMetric(avg=0.0, count=32, square=0.0, avg_ci_fn=None),\n",
       " 'p_value': AverageMetric(avg=0.7141342163085938, count=32, square=0.6318017898593098, avg_ci_fn=None),\n",
       " 'capacity': AverageMetric(avg=1.6845126152038574, count=32, square=4.185459876364575, avg_ci_fn=None),\n",
       " 'log10_p_value': AverageMetric(avg=-0.29078994494562627, count=32, square=0.3054619264695369, avg_ci_fn=None),\n",
       " 'snr': AverageMetric(avg=58.6848121881485, count=32, square=3443.9447498994255, avg_ci_fn=None),\n",
       " 'decoder_time': AverageMetric(avg=2.065990625, count=32, square=4.271666096562499, avg_ci_fn=None),\n",
       " 'qual_time': AverageMetric(avg=0.000353125, count=32, square=1.296875e-07, avg_ci_fn=None),\n",
       " 'det_time': AverageMetric(avg=0.0033281249999999995, count=32, square=0.00012251906250000005, avg_ci_fn=None),\n",
       " 'attack_time': AverageMetric(avg=0.0, count=32, square=0.0, avg_ci_fn=None)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
