{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19aa95ef-dd30-45fc-9a79-0ea23f0c5ceb",
   "metadata": {},
   "source": [
    "- To work, it requires videoseal to be installed and to be in the sylvestre/latent branch of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d816a87a-0e3e-4b26-ab88-81dda48d26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96078435-e2ae-4723-af49-69169c03e29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c691bc-4291-4634-a582-03ad0373919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompressAI package not found. Install with pip install compressai\n",
      "Diffusers package not found. Install with pip install diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/valeriu/.conda/envs/omnisealbench_all/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientViT not found.\n",
      "EfficientViT not found. Make sure to install the efficientvit package.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from videoseal.evals.full import setup_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d31f0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the message.\n",
    "msg = torch.ones((1, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981e5b0-70c1-4f6b-bcc3-931fefdfed0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a44ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import omnisealbench\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b1f25-a27f-427d-9edb-0294e0f320a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eab8acc-0d44-4e65-9f4e-581bd5507fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnisealbench.data.image import get_image_paths\n",
    "from omnisealbench.utils.common import tensor_to_message, get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874795b7-1c24-4342-9cd3-52f2a7de18c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16050"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all generated wm images in the parent directory.\n",
    "parent_dir = \"/private/home/sylvestre/avseal/avseal/logs/2021-04-03T19-39-50_cin_transformer2/samples/top_k_600_temp_1.00_top_p_0.92/0\"\n",
    "\n",
    "db = get_image_paths(parent_dir)\n",
    "len(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d5b54-9a89-4380-a287-15713b351a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22119e95-3743-4ae2-9c2c-ddd8f562fcc6",
   "metadata": {},
   "source": [
    "#### Prepare watermark .cache directory\n",
    " - as expected for the omnisealbench detection evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f9c98b8-9188-4398-809b-c63427ad49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tmp/latent_watermarking_1203c4bd-b82f-440a-a612-ddeef757dcfd')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil as sh\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "cache_dir = Path(f\"/tmp/latent_watermarking_{str(uuid.uuid4())}\")\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8ffa04-c5ff-46cb-952a-fc654a400609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 100\n",
    "\n",
    "tensor_to_message(msg[0].to(torch.int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50193e39-c2cb-4787-8ac6-d38d168f1d2d",
   "metadata": {},
   "source": [
    "- for each of the element in the dataset we need the original data, the watermarked data and the watermark message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e4d029-0d28-4600-aad0-ac45b9b65e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_message = msg[0].to(torch.int)\n",
    "\n",
    "for i, sample in enumerate(db[:num_samples]):\n",
    "    message_path = cache_dir/f\"message_{i}.txt\"\n",
    "    watermark_path = cache_dir/f\"watermark_{i}.png\"\n",
    "    data_path = cache_dir/f\"data_{i}.png\"\n",
    "\n",
    "    with open(message_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(tensor_to_message(secret_message))  # type: ignore\n",
    "    \n",
    "    sh.copy(sample, watermark_path)\n",
    "    sh.copy(sample, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677d9ad-93eb-44cd-ad81-e5b4cf878ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a3daba5-522d-4bc8-8aa4-e061cfa7b92a",
   "metadata": {},
   "source": [
    "#### STEP 1: Define the detector only for our latent watermark model since we already have generated watermarked files\n",
    "- The compatibility between model and the task:\n",
    "- For the model to be evaluated in a detection task (\"detection\"), we must implement detect_watermark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2497979-5e8c-4e2e-b784-6cf37fa7c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from omnisealbench.utils.detection import get_detection_and_decoded_keys\n",
    "\n",
    "\n",
    "\n",
    "class LatentWatermark:\n",
    "    \n",
    "    model: nn.Module\n",
    "    \n",
    "    def __init__(self, model: torch.nn.Module, img_size: float = 256, nbits: int = 64, detection_bits: int = 16):\n",
    "        self.model = model\n",
    "            \n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "        ])        \n",
    "        \n",
    "        # Each model should have an attribute 'nbits'. If the model does not have this attribute,\n",
    "        # we must set the value `message_size` in the task. If Omniseal could not find information \n",
    "        # from either model or the task, it will raise the ValueError\n",
    "        self.nbits = nbits\n",
    "        self.detection_bits = detection_bits\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def detect_watermark(\n",
    "        self,\n",
    "        contents: torch.Tensor,\n",
    "        detection_threshold: float = 0.0,\n",
    "        message_threshold: float = 0.0,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # A detect_watermark() must have a specific signature:\n",
    "        # Args:\n",
    "        #  - contents: a torch.Tensor (with batch dimension at dim=0) or a list of torch.Tensor (each without batch dimension)\n",
    "        #  - message_threshold: threshold used to convert the watermark output (probability\n",
    "        #    of each bits being 0 or 1) into the binary n-bit message.\n",
    "        #  - detection_threshold: threshold to convert the softmax output to binary indicating\n",
    "        #    the probability of the content being watermarked\n",
    "        # Returns:\n",
    "        #  - a dictionary of with some keys such as:\n",
    "        #    - \"prediction\": The prediction probability of the content being watermarked or not. The dimension should be 1 for batch size of `B`.\n",
    "        #    - \"message\": The secret message of dimension `B x nbits`\n",
    "        #    - \"detection_bits\": The list of bits reserved to calculating the detection accuracy.\n",
    "        #   \n",
    "        #    One of \"prediction\" and \"detection_bits\" must be provided. \"message\" is optional\n",
    "        #    If \"message\" is returned, Omniseal Bench will compute message accuracy scores: \"bit_acc\", \"word_acc\", \"p_value\", \"capacity\", and \"log10_p_value\"\n",
    "        #    Otherwise, these metrics will be skipped\n",
    "\n",
    "        image_tensors = []\n",
    "        for img in contents:\n",
    "            img_tensor = self.transform(img).unsqueeze(0).to(get_device(self))\n",
    "            image_tensors.append(img_tensor)\n",
    "            \n",
    "        image_tensors = torch.cat(image_tensors, dim=0)\n",
    "        extracted_bits = self.model.detector(image_tensors)[:, 1:] > 0\n",
    "\n",
    "        return get_detection_and_decoded_keys(\n",
    "            extracted_bits,\n",
    "            detection_bits=self.detection_bits,\n",
    "            detection_threshold=detection_threshold,\n",
    "            message_threshold=message_threshold,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9e98d-58ee-43dc-9e4c-84e6040d4190",
   "metadata": {},
   "source": [
    "#### STEP 2: Define the builder function.\n",
    " - The function can have any parameters, but should contain at least one parameter \"device\" which defines which device the model object will be placed too.\n",
    " - It is advisable to have the parameters() of the model class __init__() match the arguments of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f301536d-4917-4d8d-b2ff-846f76482143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_latent_watermark_model(ckpt_path: str, nbits: int = 64, detection_bits: int = 16, device: str = \"cpu\") -> LatentWatermark:    \n",
    "    watermarker = setup_model_from_checkpoint(ckpt_path)    \n",
    "    watermarker = watermarker.eval()\n",
    "    watermarker = watermarker.to(device)\n",
    "    \n",
    "    return LatentWatermark(model=watermarker, img_size=256, nbits=nbits, detection_bits=detection_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9cd4c3-3df1-4a82-9e5c-d0eb0517934a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eca840a8-8b78-4766-91fb-9008f49bceae",
   "metadata": {},
   "source": [
    "### Run the detection only task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d37ecb0a-db6d-4275-80d3-7c4410cfdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnisealbench import task, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a5555bc-9099-4a95-8b7e-884c67b6edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /checkpoint/valeriu/weights/latent_watermarker/checkpoint600.pth with message: _IncompatibleKeys(missing_keys=[], unexpected_keys=['autoencoder.model.encoder.conv_in.weight', 'autoencoder.model.encoder.conv_in.bias', 'autoencoder.model.encoder.down.0.block.0.norm1.weight', 'autoencoder.model.encoder.down.0.block.0.norm1.bias', 'autoencoder.model.encoder.down.0.block.0.conv1.weight', 'autoencoder.model.encoder.down.0.block.0.conv1.bias', 'autoencoder.model.encoder.down.0.block.0.norm2.weight', 'autoencoder.model.encoder.down.0.block.0.norm2.bias', 'autoencoder.model.encoder.down.0.block.0.conv2.weight', 'autoencoder.model.encoder.down.0.block.0.conv2.bias', 'autoencoder.model.encoder.down.0.block.1.norm1.weight', 'autoencoder.model.encoder.down.0.block.1.norm1.bias', 'autoencoder.model.encoder.down.0.block.1.conv1.weight', 'autoencoder.model.encoder.down.0.block.1.conv1.bias', 'autoencoder.model.encoder.down.0.block.1.norm2.weight', 'autoencoder.model.encoder.down.0.block.1.norm2.bias', 'autoencoder.model.encoder.down.0.block.1.conv2.weight', 'autoencoder.model.encoder.down.0.block.1.conv2.bias', 'autoencoder.model.encoder.down.0.downsample.conv.weight', 'autoencoder.model.encoder.down.0.downsample.conv.bias', 'autoencoder.model.encoder.down.1.block.0.norm1.weight', 'autoencoder.model.encoder.down.1.block.0.norm1.bias', 'autoencoder.model.encoder.down.1.block.0.conv1.weight', 'autoencoder.model.encoder.down.1.block.0.conv1.bias', 'autoencoder.model.encoder.down.1.block.0.norm2.weight', 'autoencoder.model.encoder.down.1.block.0.norm2.bias', 'autoencoder.model.encoder.down.1.block.0.conv2.weight', 'autoencoder.model.encoder.down.1.block.0.conv2.bias', 'autoencoder.model.encoder.down.1.block.1.norm1.weight', 'autoencoder.model.encoder.down.1.block.1.norm1.bias', 'autoencoder.model.encoder.down.1.block.1.conv1.weight', 'autoencoder.model.encoder.down.1.block.1.conv1.bias', 'autoencoder.model.encoder.down.1.block.1.norm2.weight', 'autoencoder.model.encoder.down.1.block.1.norm2.bias', 'autoencoder.model.encoder.down.1.block.1.conv2.weight', 'autoencoder.model.encoder.down.1.block.1.conv2.bias', 'autoencoder.model.encoder.down.1.downsample.conv.weight', 'autoencoder.model.encoder.down.1.downsample.conv.bias', 'autoencoder.model.encoder.down.2.block.0.norm1.weight', 'autoencoder.model.encoder.down.2.block.0.norm1.bias', 'autoencoder.model.encoder.down.2.block.0.conv1.weight', 'autoencoder.model.encoder.down.2.block.0.conv1.bias', 'autoencoder.model.encoder.down.2.block.0.norm2.weight', 'autoencoder.model.encoder.down.2.block.0.norm2.bias', 'autoencoder.model.encoder.down.2.block.0.conv2.weight', 'autoencoder.model.encoder.down.2.block.0.conv2.bias', 'autoencoder.model.encoder.down.2.block.0.nin_shortcut.weight', 'autoencoder.model.encoder.down.2.block.0.nin_shortcut.bias', 'autoencoder.model.encoder.down.2.block.1.norm1.weight', 'autoencoder.model.encoder.down.2.block.1.norm1.bias', 'autoencoder.model.encoder.down.2.block.1.conv1.weight', 'autoencoder.model.encoder.down.2.block.1.conv1.bias', 'autoencoder.model.encoder.down.2.block.1.norm2.weight', 'autoencoder.model.encoder.down.2.block.1.norm2.bias', 'autoencoder.model.encoder.down.2.block.1.conv2.weight', 'autoencoder.model.encoder.down.2.block.1.conv2.bias', 'autoencoder.model.encoder.down.2.downsample.conv.weight', 'autoencoder.model.encoder.down.2.downsample.conv.bias', 'autoencoder.model.encoder.down.3.block.0.norm1.weight', 'autoencoder.model.encoder.down.3.block.0.norm1.bias', 'autoencoder.model.encoder.down.3.block.0.conv1.weight', 'autoencoder.model.encoder.down.3.block.0.conv1.bias', 'autoencoder.model.encoder.down.3.block.0.norm2.weight', 'autoencoder.model.encoder.down.3.block.0.norm2.bias', 'autoencoder.model.encoder.down.3.block.0.conv2.weight', 'autoencoder.model.encoder.down.3.block.0.conv2.bias', 'autoencoder.model.encoder.down.3.block.1.norm1.weight', 'autoencoder.model.encoder.down.3.block.1.norm1.bias', 'autoencoder.model.encoder.down.3.block.1.conv1.weight', 'autoencoder.model.encoder.down.3.block.1.conv1.bias', 'autoencoder.model.encoder.down.3.block.1.norm2.weight', 'autoencoder.model.encoder.down.3.block.1.norm2.bias', 'autoencoder.model.encoder.down.3.block.1.conv2.weight', 'autoencoder.model.encoder.down.3.block.1.conv2.bias', 'autoencoder.model.encoder.down.3.downsample.conv.weight', 'autoencoder.model.encoder.down.3.downsample.conv.bias', 'autoencoder.model.encoder.down.4.block.0.norm1.weight', 'autoencoder.model.encoder.down.4.block.0.norm1.bias', 'autoencoder.model.encoder.down.4.block.0.conv1.weight', 'autoencoder.model.encoder.down.4.block.0.conv1.bias', 'autoencoder.model.encoder.down.4.block.0.norm2.weight', 'autoencoder.model.encoder.down.4.block.0.norm2.bias', 'autoencoder.model.encoder.down.4.block.0.conv2.weight', 'autoencoder.model.encoder.down.4.block.0.conv2.bias', 'autoencoder.model.encoder.down.4.block.0.nin_shortcut.weight', 'autoencoder.model.encoder.down.4.block.0.nin_shortcut.bias', 'autoencoder.model.encoder.down.4.block.1.norm1.weight', 'autoencoder.model.encoder.down.4.block.1.norm1.bias', 'autoencoder.model.encoder.down.4.block.1.conv1.weight', 'autoencoder.model.encoder.down.4.block.1.conv1.bias', 'autoencoder.model.encoder.down.4.block.1.norm2.weight', 'autoencoder.model.encoder.down.4.block.1.norm2.bias', 'autoencoder.model.encoder.down.4.block.1.conv2.weight', 'autoencoder.model.encoder.down.4.block.1.conv2.bias', 'autoencoder.model.encoder.down.4.attn.0.norm.weight', 'autoencoder.model.encoder.down.4.attn.0.norm.bias', 'autoencoder.model.encoder.down.4.attn.0.q.weight', 'autoencoder.model.encoder.down.4.attn.0.q.bias', 'autoencoder.model.encoder.down.4.attn.0.k.weight', 'autoencoder.model.encoder.down.4.attn.0.k.bias', 'autoencoder.model.encoder.down.4.attn.0.v.weight', 'autoencoder.model.encoder.down.4.attn.0.v.bias', 'autoencoder.model.encoder.down.4.attn.0.proj_out.weight', 'autoencoder.model.encoder.down.4.attn.0.proj_out.bias', 'autoencoder.model.encoder.down.4.attn.1.norm.weight', 'autoencoder.model.encoder.down.4.attn.1.norm.bias', 'autoencoder.model.encoder.down.4.attn.1.q.weight', 'autoencoder.model.encoder.down.4.attn.1.q.bias', 'autoencoder.model.encoder.down.4.attn.1.k.weight', 'autoencoder.model.encoder.down.4.attn.1.k.bias', 'autoencoder.model.encoder.down.4.attn.1.v.weight', 'autoencoder.model.encoder.down.4.attn.1.v.bias', 'autoencoder.model.encoder.down.4.attn.1.proj_out.weight', 'autoencoder.model.encoder.down.4.attn.1.proj_out.bias', 'autoencoder.model.encoder.mid.block_1.norm1.weight', 'autoencoder.model.encoder.mid.block_1.norm1.bias', 'autoencoder.model.encoder.mid.block_1.conv1.weight', 'autoencoder.model.encoder.mid.block_1.conv1.bias', 'autoencoder.model.encoder.mid.block_1.norm2.weight', 'autoencoder.model.encoder.mid.block_1.norm2.bias', 'autoencoder.model.encoder.mid.block_1.conv2.weight', 'autoencoder.model.encoder.mid.block_1.conv2.bias', 'autoencoder.model.encoder.mid.attn_1.norm.weight', 'autoencoder.model.encoder.mid.attn_1.norm.bias', 'autoencoder.model.encoder.mid.attn_1.q.weight', 'autoencoder.model.encoder.mid.attn_1.q.bias', 'autoencoder.model.encoder.mid.attn_1.k.weight', 'autoencoder.model.encoder.mid.attn_1.k.bias', 'autoencoder.model.encoder.mid.attn_1.v.weight', 'autoencoder.model.encoder.mid.attn_1.v.bias', 'autoencoder.model.encoder.mid.attn_1.proj_out.weight', 'autoencoder.model.encoder.mid.attn_1.proj_out.bias', 'autoencoder.model.encoder.mid.block_2.norm1.weight', 'autoencoder.model.encoder.mid.block_2.norm1.bias', 'autoencoder.model.encoder.mid.block_2.conv1.weight', 'autoencoder.model.encoder.mid.block_2.conv1.bias', 'autoencoder.model.encoder.mid.block_2.norm2.weight', 'autoencoder.model.encoder.mid.block_2.norm2.bias', 'autoencoder.model.encoder.mid.block_2.conv2.weight', 'autoencoder.model.encoder.mid.block_2.conv2.bias', 'autoencoder.model.encoder.norm_out.weight', 'autoencoder.model.encoder.norm_out.bias', 'autoencoder.model.encoder.conv_out.weight', 'autoencoder.model.encoder.conv_out.bias', 'autoencoder.model.decoder.conv_in.weight', 'autoencoder.model.decoder.conv_in.bias', 'autoencoder.model.decoder.mid.block_1.norm1.weight', 'autoencoder.model.decoder.mid.block_1.norm1.bias', 'autoencoder.model.decoder.mid.block_1.conv1.weight', 'autoencoder.model.decoder.mid.block_1.conv1.bias', 'autoencoder.model.decoder.mid.block_1.norm2.weight', 'autoencoder.model.decoder.mid.block_1.norm2.bias', 'autoencoder.model.decoder.mid.block_1.conv2.weight', 'autoencoder.model.decoder.mid.block_1.conv2.bias', 'autoencoder.model.decoder.mid.attn_1.norm.weight', 'autoencoder.model.decoder.mid.attn_1.norm.bias', 'autoencoder.model.decoder.mid.attn_1.q.weight', 'autoencoder.model.decoder.mid.attn_1.q.bias', 'autoencoder.model.decoder.mid.attn_1.k.weight', 'autoencoder.model.decoder.mid.attn_1.k.bias', 'autoencoder.model.decoder.mid.attn_1.v.weight', 'autoencoder.model.decoder.mid.attn_1.v.bias', 'autoencoder.model.decoder.mid.attn_1.proj_out.weight', 'autoencoder.model.decoder.mid.attn_1.proj_out.bias', 'autoencoder.model.decoder.mid.block_2.norm1.weight', 'autoencoder.model.decoder.mid.block_2.norm1.bias', 'autoencoder.model.decoder.mid.block_2.conv1.weight', 'autoencoder.model.decoder.mid.block_2.conv1.bias', 'autoencoder.model.decoder.mid.block_2.norm2.weight', 'autoencoder.model.decoder.mid.block_2.norm2.bias', 'autoencoder.model.decoder.mid.block_2.conv2.weight', 'autoencoder.model.decoder.mid.block_2.conv2.bias', 'autoencoder.model.decoder.up.0.block.0.norm1.weight', 'autoencoder.model.decoder.up.0.block.0.norm1.bias', 'autoencoder.model.decoder.up.0.block.0.conv1.weight', 'autoencoder.model.decoder.up.0.block.0.conv1.bias', 'autoencoder.model.decoder.up.0.block.0.norm2.weight', 'autoencoder.model.decoder.up.0.block.0.norm2.bias', 'autoencoder.model.decoder.up.0.block.0.conv2.weight', 'autoencoder.model.decoder.up.0.block.0.conv2.bias', 'autoencoder.model.decoder.up.0.block.1.norm1.weight', 'autoencoder.model.decoder.up.0.block.1.norm1.bias', 'autoencoder.model.decoder.up.0.block.1.conv1.weight', 'autoencoder.model.decoder.up.0.block.1.conv1.bias', 'autoencoder.model.decoder.up.0.block.1.norm2.weight', 'autoencoder.model.decoder.up.0.block.1.norm2.bias', 'autoencoder.model.decoder.up.0.block.1.conv2.weight', 'autoencoder.model.decoder.up.0.block.1.conv2.bias', 'autoencoder.model.decoder.up.0.block.2.norm1.weight', 'autoencoder.model.decoder.up.0.block.2.norm1.bias', 'autoencoder.model.decoder.up.0.block.2.conv1.weight', 'autoencoder.model.decoder.up.0.block.2.conv1.bias', 'autoencoder.model.decoder.up.0.block.2.norm2.weight', 'autoencoder.model.decoder.up.0.block.2.norm2.bias', 'autoencoder.model.decoder.up.0.block.2.conv2.weight', 'autoencoder.model.decoder.up.0.block.2.conv2.bias', 'autoencoder.model.decoder.up.1.block.0.norm1.weight', 'autoencoder.model.decoder.up.1.block.0.norm1.bias', 'autoencoder.model.decoder.up.1.block.0.conv1.weight', 'autoencoder.model.decoder.up.1.block.0.conv1.bias', 'autoencoder.model.decoder.up.1.block.0.norm2.weight', 'autoencoder.model.decoder.up.1.block.0.norm2.bias', 'autoencoder.model.decoder.up.1.block.0.conv2.weight', 'autoencoder.model.decoder.up.1.block.0.conv2.bias', 'autoencoder.model.decoder.up.1.block.0.nin_shortcut.weight', 'autoencoder.model.decoder.up.1.block.0.nin_shortcut.bias', 'autoencoder.model.decoder.up.1.block.1.norm1.weight', 'autoencoder.model.decoder.up.1.block.1.norm1.bias', 'autoencoder.model.decoder.up.1.block.1.conv1.weight', 'autoencoder.model.decoder.up.1.block.1.conv1.bias', 'autoencoder.model.decoder.up.1.block.1.norm2.weight', 'autoencoder.model.decoder.up.1.block.1.norm2.bias', 'autoencoder.model.decoder.up.1.block.1.conv2.weight', 'autoencoder.model.decoder.up.1.block.1.conv2.bias', 'autoencoder.model.decoder.up.1.block.2.norm1.weight', 'autoencoder.model.decoder.up.1.block.2.norm1.bias', 'autoencoder.model.decoder.up.1.block.2.conv1.weight', 'autoencoder.model.decoder.up.1.block.2.conv1.bias', 'autoencoder.model.decoder.up.1.block.2.norm2.weight', 'autoencoder.model.decoder.up.1.block.2.norm2.bias', 'autoencoder.model.decoder.up.1.block.2.conv2.weight', 'autoencoder.model.decoder.up.1.block.2.conv2.bias', 'autoencoder.model.decoder.up.1.upsample.conv.weight', 'autoencoder.model.decoder.up.1.upsample.conv.bias', 'autoencoder.model.decoder.up.2.block.0.norm1.weight', 'autoencoder.model.decoder.up.2.block.0.norm1.bias', 'autoencoder.model.decoder.up.2.block.0.conv1.weight', 'autoencoder.model.decoder.up.2.block.0.conv1.bias', 'autoencoder.model.decoder.up.2.block.0.norm2.weight', 'autoencoder.model.decoder.up.2.block.0.norm2.bias', 'autoencoder.model.decoder.up.2.block.0.conv2.weight', 'autoencoder.model.decoder.up.2.block.0.conv2.bias', 'autoencoder.model.decoder.up.2.block.1.norm1.weight', 'autoencoder.model.decoder.up.2.block.1.norm1.bias', 'autoencoder.model.decoder.up.2.block.1.conv1.weight', 'autoencoder.model.decoder.up.2.block.1.conv1.bias', 'autoencoder.model.decoder.up.2.block.1.norm2.weight', 'autoencoder.model.decoder.up.2.block.1.norm2.bias', 'autoencoder.model.decoder.up.2.block.1.conv2.weight', 'autoencoder.model.decoder.up.2.block.1.conv2.bias', 'autoencoder.model.decoder.up.2.block.2.norm1.weight', 'autoencoder.model.decoder.up.2.block.2.norm1.bias', 'autoencoder.model.decoder.up.2.block.2.conv1.weight', 'autoencoder.model.decoder.up.2.block.2.conv1.bias', 'autoencoder.model.decoder.up.2.block.2.norm2.weight', 'autoencoder.model.decoder.up.2.block.2.norm2.bias', 'autoencoder.model.decoder.up.2.block.2.conv2.weight', 'autoencoder.model.decoder.up.2.block.2.conv2.bias', 'autoencoder.model.decoder.up.2.upsample.conv.weight', 'autoencoder.model.decoder.up.2.upsample.conv.bias', 'autoencoder.model.decoder.up.3.block.0.norm1.weight', 'autoencoder.model.decoder.up.3.block.0.norm1.bias', 'autoencoder.model.decoder.up.3.block.0.conv1.weight', 'autoencoder.model.decoder.up.3.block.0.conv1.bias', 'autoencoder.model.decoder.up.3.block.0.norm2.weight', 'autoencoder.model.decoder.up.3.block.0.norm2.bias', 'autoencoder.model.decoder.up.3.block.0.conv2.weight', 'autoencoder.model.decoder.up.3.block.0.conv2.bias', 'autoencoder.model.decoder.up.3.block.0.nin_shortcut.weight', 'autoencoder.model.decoder.up.3.block.0.nin_shortcut.bias', 'autoencoder.model.decoder.up.3.block.1.norm1.weight', 'autoencoder.model.decoder.up.3.block.1.norm1.bias', 'autoencoder.model.decoder.up.3.block.1.conv1.weight', 'autoencoder.model.decoder.up.3.block.1.conv1.bias', 'autoencoder.model.decoder.up.3.block.1.norm2.weight', 'autoencoder.model.decoder.up.3.block.1.norm2.bias', 'autoencoder.model.decoder.up.3.block.1.conv2.weight', 'autoencoder.model.decoder.up.3.block.1.conv2.bias', 'autoencoder.model.decoder.up.3.block.2.norm1.weight', 'autoencoder.model.decoder.up.3.block.2.norm1.bias', 'autoencoder.model.decoder.up.3.block.2.conv1.weight', 'autoencoder.model.decoder.up.3.block.2.conv1.bias', 'autoencoder.model.decoder.up.3.block.2.norm2.weight', 'autoencoder.model.decoder.up.3.block.2.norm2.bias', 'autoencoder.model.decoder.up.3.block.2.conv2.weight', 'autoencoder.model.decoder.up.3.block.2.conv2.bias', 'autoencoder.model.decoder.up.3.upsample.conv.weight', 'autoencoder.model.decoder.up.3.upsample.conv.bias', 'autoencoder.model.decoder.up.4.block.0.norm1.weight', 'autoencoder.model.decoder.up.4.block.0.norm1.bias', 'autoencoder.model.decoder.up.4.block.0.conv1.weight', 'autoencoder.model.decoder.up.4.block.0.conv1.bias', 'autoencoder.model.decoder.up.4.block.0.norm2.weight', 'autoencoder.model.decoder.up.4.block.0.norm2.bias', 'autoencoder.model.decoder.up.4.block.0.conv2.weight', 'autoencoder.model.decoder.up.4.block.0.conv2.bias', 'autoencoder.model.decoder.up.4.block.1.norm1.weight', 'autoencoder.model.decoder.up.4.block.1.norm1.bias', 'autoencoder.model.decoder.up.4.block.1.conv1.weight', 'autoencoder.model.decoder.up.4.block.1.conv1.bias', 'autoencoder.model.decoder.up.4.block.1.norm2.weight', 'autoencoder.model.decoder.up.4.block.1.norm2.bias', 'autoencoder.model.decoder.up.4.block.1.conv2.weight', 'autoencoder.model.decoder.up.4.block.1.conv2.bias', 'autoencoder.model.decoder.up.4.block.2.norm1.weight', 'autoencoder.model.decoder.up.4.block.2.norm1.bias', 'autoencoder.model.decoder.up.4.block.2.conv1.weight', 'autoencoder.model.decoder.up.4.block.2.conv1.bias', 'autoencoder.model.decoder.up.4.block.2.norm2.weight', 'autoencoder.model.decoder.up.4.block.2.norm2.bias', 'autoencoder.model.decoder.up.4.block.2.conv2.weight', 'autoencoder.model.decoder.up.4.block.2.conv2.bias', 'autoencoder.model.decoder.up.4.attn.0.norm.weight', 'autoencoder.model.decoder.up.4.attn.0.norm.bias', 'autoencoder.model.decoder.up.4.attn.0.q.weight', 'autoencoder.model.decoder.up.4.attn.0.q.bias', 'autoencoder.model.decoder.up.4.attn.0.k.weight', 'autoencoder.model.decoder.up.4.attn.0.k.bias', 'autoencoder.model.decoder.up.4.attn.0.v.weight', 'autoencoder.model.decoder.up.4.attn.0.v.bias', 'autoencoder.model.decoder.up.4.attn.0.proj_out.weight', 'autoencoder.model.decoder.up.4.attn.0.proj_out.bias', 'autoencoder.model.decoder.up.4.attn.1.norm.weight', 'autoencoder.model.decoder.up.4.attn.1.norm.bias', 'autoencoder.model.decoder.up.4.attn.1.q.weight', 'autoencoder.model.decoder.up.4.attn.1.q.bias', 'autoencoder.model.decoder.up.4.attn.1.k.weight', 'autoencoder.model.decoder.up.4.attn.1.k.bias', 'autoencoder.model.decoder.up.4.attn.1.v.weight', 'autoencoder.model.decoder.up.4.attn.1.v.bias', 'autoencoder.model.decoder.up.4.attn.1.proj_out.weight', 'autoencoder.model.decoder.up.4.attn.1.proj_out.bias', 'autoencoder.model.decoder.up.4.attn.2.norm.weight', 'autoencoder.model.decoder.up.4.attn.2.norm.bias', 'autoencoder.model.decoder.up.4.attn.2.q.weight', 'autoencoder.model.decoder.up.4.attn.2.q.bias', 'autoencoder.model.decoder.up.4.attn.2.k.weight', 'autoencoder.model.decoder.up.4.attn.2.k.bias', 'autoencoder.model.decoder.up.4.attn.2.v.weight', 'autoencoder.model.decoder.up.4.attn.2.v.bias', 'autoencoder.model.decoder.up.4.attn.2.proj_out.weight', 'autoencoder.model.decoder.up.4.attn.2.proj_out.bias', 'autoencoder.model.decoder.up.4.upsample.conv.weight', 'autoencoder.model.decoder.up.4.upsample.conv.bias', 'autoencoder.model.decoder.norm_out.weight', 'autoencoder.model.decoder.norm_out.bias', 'autoencoder.model.decoder.conv_out.weight', 'autoencoder.model.decoder.conv_out.bias', 'autoencoder.model.quantize.embedding.weight', 'autoencoder.model.quant_conv.weight', 'autoencoder.model.quant_conv.bias', 'autoencoder.model.post_quant_conv.weight', 'autoencoder.model.post_quant_conv.bias'])\n",
      "Running ImageWatermarkAttacksAndDetection with attack: identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/valeriu/.conda/envs/omnisealbench_all/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/private/home/valeriu/.conda/envs/omnisealbench_all/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ImageWatermarkAttacksAndDetection with attack: gaussian_blur__kernel_size_3\n",
      "Running ImageWatermarkAttacksAndDetection with attack: gaussian_blur__kernel_size_5\n",
      "Running ImageWatermarkAttacksAndDetection with attack: gaussian_blur__kernel_size_9\n",
      "Running ImageWatermarkAttacksAndDetection with attack: gaussian_blur__kernel_size_13\n",
      "Running ImageWatermarkAttacksAndDetection with attack: gaussian_blur__kernel_size_17\n",
      "Running ImageWatermarkAttacksAndDetection with attack: comb\n"
     ]
    }
   ],
   "source": [
    "detection_task = task(\n",
    "    \"detection\",\n",
    "    modality=\"image\",\n",
    "    seed=42,\n",
    "    dataset_dir=str(cache_dir),\n",
    "    original_image_pattern=\"data*.png\",\n",
    "    watermarked_image_pattern=\"watermark*.png\",  # We just fake the watermarked images\n",
    "    message_pattern=\"message_*.txt\",\n",
    "    # metrics=\"all\",  # We can add one more quality metric that was not previously computed\n",
    "    metrics=['lpips', 'psnr', 'ssim'],\n",
    "    # result_dir=\"/tmp/detection_image\",\n",
    "    # overwrite=True,\n",
    "    attacks=[\"comb\", \"gaussian_blur\"],\n",
    "    batch_size=2,\n",
    ")\n",
    "\n",
    "detector = get_model(\n",
    "    build_latent_watermark_model, \n",
    "    as_type=\"detector\", device=\"cuda\", \n",
    "    ckpt_path='/checkpoint/valeriu/weights/latent_watermarker/checkpoint600.pth',\n",
    "    nbits=64,\n",
    "    detection_bits=16,\n",
    ")\n",
    "\n",
    "avg_metrics, raw_results = detection_task(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66845831-752f-4dab-8a15-41f7d6e4ca53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0da9c955-c752-42d3-903d-c1d168d682c9",
   "metadata": {},
   "source": [
    "Note: here the averages should take in account/weight the number of variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7afdb9f-ddc3-4f39-9a62-a3e8782055aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'watermark_det_score': AverageMetric(avg=0.9300892857142857, count=700, square=0.8720256696428571, avg_ci_fn=None),\n",
       " 'watermark_det': AverageMetric(avg=0.9985714285714286, count=700, square=0.9985714285714286, avg_ci_fn=None),\n",
       " 'fake_det_score': AverageMetric(avg=0.9300892857142857, count=700, square=0.8720256696428571, avg_ci_fn=None),\n",
       " 'fake_det': AverageMetric(avg=0.9985714285714286, count=700, square=0.9985714285714286, avg_ci_fn=None),\n",
       " 'bit_acc': AverageMetric(avg=0.9153869238921574, count=700, square=0.8445976291478626, avg_ci_fn=None),\n",
       " 'word_acc': AverageMetric(avg=0.08571428571428572, count=700, square=0.08571428571428572, avg_ci_fn=None),\n",
       " 'p_value': AverageMetric(avg=0.0047896499597762906, count=700, square=0.002258927683709689, avg_ci_fn=None),\n",
       " 'capacity': AverageMetric(avg=30.414895470482964, count=700, square=1038.6499686100688, avg_ci_fn=None),\n",
       " 'log10_p_value': AverageMetric(avg=-9.704717900215343, count=700, square=103.64760890944434, avg_ci_fn=None),\n",
       " 'ssim': AverageMetric(avg=1.0, count=600, square=1.0, avg_ci_fn=None),\n",
       " 'lpips': AverageMetric(avg=0.0, count=600, square=0.0, avg_ci_fn=None),\n",
       " 'psnr': AverageMetric(avg=inf, count=600, square=inf, avg_ci_fn=None),\n",
       " 'decoder_time': AverageMetric(avg=0.00407142857142857, count=700, square=1.669319999999998e-05, avg_ci_fn=None),\n",
       " 'qual_time': AverageMetric(avg=0.14131857142857138, count=700, square=0.03038773157142857, avg_ci_fn=None),\n",
       " 'det_time': AverageMetric(avg=0.0006997142857142859, count=700, square=5.045999999999993e-07, avg_ci_fn=None),\n",
       " 'attack_time': AverageMetric(avg=0.0007617142857142868, count=700, square=8.801714285714271e-07, avg_ci_fn=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be4453-f80f-4f35-b372-665bdcfdbb57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "989bf60a-f6ee-4382-9bb8-f7987c8512c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>watermark_det_score</th>\n",
       "      <th>watermark_det</th>\n",
       "      <th>fake_det_score</th>\n",
       "      <th>fake_det</th>\n",
       "      <th>bit_acc</th>\n",
       "      <th>word_acc</th>\n",
       "      <th>p_value</th>\n",
       "      <th>capacity</th>\n",
       "      <th>log10_p_value</th>\n",
       "      <th>ssim</th>\n",
       "      <th>lpips</th>\n",
       "      <th>psnr</th>\n",
       "      <th>decoder_time</th>\n",
       "      <th>qual_time</th>\n",
       "      <th>det_time</th>\n",
       "      <th>attack_time</th>\n",
       "      <th>idx</th>\n",
       "      <th>attack</th>\n",
       "      <th>attack_variant</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9375</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>-14.449440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>identity</td>\n",
       "      <td>default</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>-14.449440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>identity</td>\n",
       "      <td>default</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8750</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>True</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>False</td>\n",
       "      <td>6.562928e-11</td>\n",
       "      <td>31.810078</td>\n",
       "      <td>-10.182902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>identity</td>\n",
       "      <td>default</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>False</td>\n",
       "      <td>6.562928e-11</td>\n",
       "      <td>31.810078</td>\n",
       "      <td>-10.182902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>identity</td>\n",
       "      <td>default</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>False</td>\n",
       "      <td>3.120204e-07</td>\n",
       "      <td>19.232918</td>\n",
       "      <td>-6.505817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>identity</td>\n",
       "      <td>default</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>True</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>False</td>\n",
       "      <td>3.120204e-07</td>\n",
       "      <td>19.232918</td>\n",
       "      <td>-6.505817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>95</td>\n",
       "      <td>comb</td>\n",
       "      <td>default</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>True</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>False</td>\n",
       "      <td>1.111225e-04</td>\n",
       "      <td>10.725326</td>\n",
       "      <td>-3.954198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>96</td>\n",
       "      <td>comb</td>\n",
       "      <td>default</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>True</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>7.569163e-10</td>\n",
       "      <td>28.136793</td>\n",
       "      <td>-9.120952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>97</td>\n",
       "      <td>comb</td>\n",
       "      <td>default</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>False</td>\n",
       "      <td>6.641641e-03</td>\n",
       "      <td>4.990165</td>\n",
       "      <td>-2.177725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>98</td>\n",
       "      <td>comb</td>\n",
       "      <td>default</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>True</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>False</td>\n",
       "      <td>2.757601e-03</td>\n",
       "      <td>6.198509</td>\n",
       "      <td>-2.559469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>99</td>\n",
       "      <td>comb</td>\n",
       "      <td>default</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     watermark_det_score  watermark_det  fake_det_score  fake_det   bit_acc  \\\n",
       "0                 0.9375           True          0.9375      True  1.000000   \n",
       "1                 1.0000           True          1.0000      True  1.000000   \n",
       "2                 0.8750           True          0.8750      True  0.937500   \n",
       "3                 1.0000           True          1.0000      True  0.937500   \n",
       "4                 1.0000           True          1.0000      True  0.854167   \n",
       "..                   ...            ...             ...       ...       ...   \n",
       "695               0.8125           True          0.8125      True  0.854167   \n",
       "696               0.6875           True          0.6875      True  0.770833   \n",
       "697               0.8125           True          0.8125      True  0.916667   \n",
       "698               1.0000           True          1.0000      True  0.687500   \n",
       "699               0.8125           True          0.8125      True  0.708333   \n",
       "\n",
       "     word_acc       p_value   capacity  log10_p_value  ssim  lpips  psnr  \\\n",
       "0        True  3.552714e-15  48.000000     -14.449440   1.0    0.0   inf   \n",
       "1        True  3.552714e-15  48.000000     -14.449440   1.0    0.0   inf   \n",
       "2       False  6.562928e-11  31.810078     -10.182902   1.0    0.0   inf   \n",
       "3       False  6.562928e-11  31.810078     -10.182902   1.0    0.0   inf   \n",
       "4       False  3.120204e-07  19.232918      -6.505817   1.0    0.0   inf   \n",
       "..        ...           ...        ...            ...   ...    ...   ...   \n",
       "695     False  3.120204e-07  19.232918      -6.505817   NaN    NaN   NaN   \n",
       "696     False  1.111225e-04  10.725326      -3.954198   NaN    NaN   NaN   \n",
       "697     False  7.569163e-10  28.136793      -9.120952   NaN    NaN   NaN   \n",
       "698     False  6.641641e-03   4.990165      -2.177725   NaN    NaN   NaN   \n",
       "699     False  2.757601e-03   6.198509      -2.559469   NaN    NaN   NaN   \n",
       "\n",
       "     decoder_time  qual_time  det_time  attack_time  idx    attack  \\\n",
       "0          0.0053     0.8697    0.0019       0.0000    0  identity   \n",
       "1          0.0053     0.8697    0.0019       0.0000    1  identity   \n",
       "2          0.0039     0.2102    0.0007       0.0000    2  identity   \n",
       "3          0.0039     0.2102    0.0007       0.0000    3  identity   \n",
       "4          0.0041     0.2067    0.0008       0.0000    4  identity   \n",
       "..            ...        ...       ...          ...  ...       ...   \n",
       "695        0.0034     0.0000    0.0005       0.0019   95      comb   \n",
       "696        0.0034     0.0000    0.0005       0.0019   96      comb   \n",
       "697        0.0034     0.0000    0.0005       0.0019   97      comb   \n",
       "698        0.0034     0.0000    0.0005       0.0019   98      comb   \n",
       "699        0.0034     0.0000    0.0005       0.0019   99      comb   \n",
       "\n",
       "    attack_variant    cat  \n",
       "0          default   none  \n",
       "1          default   none  \n",
       "2          default   none  \n",
       "3          default   none  \n",
       "4          default   none  \n",
       "..             ...    ...  \n",
       "695        default  Mixed  \n",
       "696        default  Mixed  \n",
       "697        default  Mixed  \n",
       "698        default  Mixed  \n",
       "699        default  Mixed  \n",
       "\n",
       "[700 rows x 20 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = detection_task.print_scores(raw_results)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cd7ec-66c9-4ac7-aac7-6ed8cec034c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f13b5-35a3-46ed-99cf-b473d95fe99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9564dce2-43c0-4fae-9fef-4facb0114d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnisealbench.utils.analysis import aggregate_by_attacks, aggregate_by_attack_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b57548b-326b-4eaa-9ff3-1b4f7b6afde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack</th>\n",
       "      <th>cat</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>lpips</th>\n",
       "      <th>bit_acc</th>\n",
       "      <th>log10_p_value</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>watermark_det_score</th>\n",
       "      <th>fake_det_score</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comb</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756875</td>\n",
       "      <td>-4.069825</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.808750</td>\n",
       "      <td>0.808750</td>\n",
       "      <td>11.274060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaussian_blur</td>\n",
       "      <td>Visual</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941625</td>\n",
       "      <td>-10.627832</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.949625</td>\n",
       "      <td>0.949625</td>\n",
       "      <td>33.546480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identity</td>\n",
       "      <td>none</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>-10.724038</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>33.897807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          attack     cat  psnr  ssim  lpips   bit_acc  log10_p_value   TPR  \\\n",
       "0           comb   Mixed   NaN   NaN    NaN  0.756875      -4.069825  0.99   \n",
       "1  gaussian_blur  Visual   inf   1.0    0.0  0.941625     -10.627832  1.00   \n",
       "2       identity    none   inf   1.0    0.0  0.942708     -10.724038  1.00   \n",
       "\n",
       "    FPR  watermark_det_score  fake_det_score   capacity  \n",
       "0  0.99             0.808750        0.808750  11.274060  \n",
       "1  1.00             0.949625        0.949625  33.546480  \n",
       "2  1.00             0.953750        0.953750  33.897807  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_by_attacks(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c94fd3-819f-4438-9245-2b4bd8c11aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f08e8c0-d2aa-46b9-a296-67330a039ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack</th>\n",
       "      <th>attack_variant</th>\n",
       "      <th>cat</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>lpips</th>\n",
       "      <th>bit_acc</th>\n",
       "      <th>log10_p_value</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>watermark_det_score</th>\n",
       "      <th>fake_det_score</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comb</td>\n",
       "      <td>default</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756875</td>\n",
       "      <td>-4.069825</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.808750</td>\n",
       "      <td>0.808750</td>\n",
       "      <td>11.274060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaussian_blur</td>\n",
       "      <td>kernel_size_13</td>\n",
       "      <td>Visual</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>-10.572671</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.946250</td>\n",
       "      <td>0.946250</td>\n",
       "      <td>33.348233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaussian_blur</td>\n",
       "      <td>kernel_size_17</td>\n",
       "      <td>Visual</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>-10.398696</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>32.723669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaussian_blur</td>\n",
       "      <td>kernel_size_3</td>\n",
       "      <td>Visual</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>-10.750516</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>34.014827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaussian_blur</td>\n",
       "      <td>kernel_size_5</td>\n",
       "      <td>Visual</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>-10.682998</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>33.742841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gaussian_blur</td>\n",
       "      <td>kernel_size_9</td>\n",
       "      <td>Visual</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.943958</td>\n",
       "      <td>-10.734281</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>33.902831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>identity</td>\n",
       "      <td>default</td>\n",
       "      <td>none</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>-10.724038</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>33.897807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          attack  attack_variant     cat  psnr  ssim  lpips   bit_acc  \\\n",
       "0           comb         default   Mixed   NaN   NaN    NaN  0.756875   \n",
       "1  gaussian_blur  kernel_size_13  Visual   inf   1.0    0.0  0.940833   \n",
       "2  gaussian_blur  kernel_size_17  Visual   inf   1.0    0.0  0.937500   \n",
       "3  gaussian_blur   kernel_size_3  Visual   inf   1.0    0.0  0.943333   \n",
       "4  gaussian_blur   kernel_size_5  Visual   inf   1.0    0.0  0.942500   \n",
       "5  gaussian_blur   kernel_size_9  Visual   inf   1.0    0.0  0.943958   \n",
       "6       identity         default    none   inf   1.0    0.0  0.942708   \n",
       "\n",
       "   log10_p_value   TPR   FPR  watermark_det_score  fake_det_score   capacity  \n",
       "0      -4.069825  0.99  0.99             0.808750        0.808750  11.274060  \n",
       "1     -10.572671  1.00  1.00             0.946250        0.946250  33.348233  \n",
       "2     -10.398696  1.00  1.00             0.945625        0.945625  32.723669  \n",
       "3     -10.750516  1.00  1.00             0.953750        0.953750  34.014827  \n",
       "4     -10.682998  1.00  1.00             0.952500        0.952500  33.742841  \n",
       "5     -10.734281  1.00  1.00             0.950000        0.950000  33.902831  \n",
       "6     -10.724038  1.00  1.00             0.953750        0.953750  33.897807  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_by_attack_variants(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d551ce-f4ba-4060-8a2f-0bcdedc04307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
